{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install python-dotenv\n",
    "#!uv pip install cerebras_cloud_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from cerebras.cloud.sdk import Cerebras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('CEREBRAS_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Cerebras(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Albin! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today? Is there anything particular you'd like to chat about or any way I can assist you?"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"I am Albin how are you?\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"qwen-3-coder-480b\",\n",
    "    stream=True,\n",
    "    max_completion_tokens=40000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Qwen3, the latest large language model launched by Alibaba, with an ultra-large-scale parameter count exceeding 10 billion. I support multilingual interaction and have significant improvements in code writing, logical reasoning, multimodal processing, and more. For specific technical details, please refer to Alibaba's official website."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"pls be very brief in your answer, what model are you, release details?\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"qwen-3-coder-480b\",\n",
    "    stream=True,\n",
    "    max_completion_tokens=40000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLAUDE_CODE_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
